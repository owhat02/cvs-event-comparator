
import streamlit as st
import os
import pandas as pd

st.set_page_config(page_title="í¸ì˜ì  í–‰ì‚¬ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸª", layout="wide")

# CSS ë¡œë“œ (ëª¨ë“  í˜ì´ì§€ ê³µí†µ)
if os.path.exists("style.css"):
    with open("style.css", encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# ë°ì´í„° ë¡œë“œ (ì‚¬ì´ë“œë°” í†µê³„ìš©)
@st.cache_data(ttl=3600)
def get_summary_stats():
    file_path = os.path.join('data', 'categorized_data.csv')
    if not os.path.exists(file_path):
        return None
    df = pd.read_csv(file_path)
    return {
        "total_count": len(df),
        "brands_count": len(df['brand'].unique())
    }

# ì‚¬ì´ë“œë°” ê³µí†µ ì˜ì—­
def show_sidebar():
    stats = get_summary_stats()
    if stats:
        st.sidebar.markdown("### ğŸ“Š ì‹¤ì‹œê°„ í˜„í™©")
        st.sidebar.write(f"âœ… ì´ í–‰ì‚¬ ìƒí’ˆ: **{stats['total_count']:,}ê°œ**")
        st.sidebar.write(f"ğŸ¢ ì°¸ì—¬ ë¸Œëœë“œ: **{stats['brands_count']}ê°œ**")
    
    st.sidebar.markdown("---")
    st.sidebar.caption("Â© 2026 Convenience Store Dashboard")

# í˜ì´ì§€ ì •ì˜
home_page = st.Page("pages/00_home.py", title="ğŸ  ë©”ì¸ë³´ë“œ", default=True)
summary_page = st.Page("pages/01_overall_summary.py", title="ğŸ” ì „ì²´ ìš”ì•½")
comparison_page = st.Page("pages/02_brand_comparison.py", title="ğŸ“Š ë¸Œëœë“œ ë¹„êµ")
best_value_page = st.Page("pages/03_best_value.py", title="ğŸ’ ê°€ì„±ë¹„ TOP 50")

# ë‚´ë¹„ê²Œì´ì…˜ êµ¬ì„±
pg = st.navigation({
    "ëŒ€ì‹œë³´ë“œ": [home_page],
    "ìƒì„¸ ì„œë¹„ìŠ¤": [summary_page, comparison_page, best_value_page]
})

# ì‚¬ì´ë“œë°” ì‹¤í–‰
show_sidebar()

# í˜ì´ì§€ ì‹¤í–‰
pg.run()

from scraper import cu_scraper, gs25_scraper, seven_eleven_scraper, emart24_scraper
import time
import os
from datetime import datetime

def run_all_scrapers():
    """
    í¸ì˜ì  ë°ì´í„° í†µí•© ìˆ˜ì§‘ ì—”ì§„ (Test Runner)
    ëª¨ë“  ë¸Œëœë“œì˜ ìŠ¤í¬ë˜í¼ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.
    """
    # ì €ì¥ í´ë” ì‚¬ì „ ìƒì„±
    os.makedirs("data", exist_ok=True)
    
    start_time = time.time()
    
    print("\n" + "â•" * 60)
    print(f" ğŸª CONV-DASHBOARD DATA COLLECTOR v1.0")
    print(f" ğŸ“… ì‹¤í–‰ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("â•" * 60)
    
    # ì‹¤í–‰ ëŒ€ìƒ ìŠ¤í¬ë˜í¼ ë¦¬ìŠ¤íŠ¸
    scrapers = [
        ("CU", cu_scraper),
        ("GS25", gs25_scraper),
        ("7-Eleven", seven_eleven_scraper),
        ("emart24", emart24_scraper)
    ]
    
    success_count = 0
    
    for brand, module in scrapers:
        try:
            # ê° ìŠ¤í¬ë˜í¼ ë‚´ë¶€ì—ì„œ ìƒì„¸ ë¡œê·¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
            module.scrape()
            success_count += 1
            print(f" ğŸ {brand} í”„ë¡œì„¸ìŠ¤ ì •ìƒ ì¢…ë£Œ")
            print("-" * 40)
        except Exception as e:
            print(f"\n âŒ [{brand}] ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")
            print("-" * 40)
            
    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "â•" * 60)
    print(f" ì „ì²´ ìˆ˜ì§‘ ì‘ì—… ì™„ë£Œ ({success_count}/{len(scrapers)})")
    print(f" ì´ ì†Œìš” ì‹œê°„: {int(duration // 60)}ë¶„ {int(duration % 60)}ì´ˆ")
    print(f" ë°ì´í„° ìœ„ì¹˜: {os.path.abspath('data')}")
    print("â•" * 60 + "\n")

if __name__ == "__main__":
    run_all_scrapers()

