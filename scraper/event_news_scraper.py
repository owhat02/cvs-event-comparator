from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time
from datetime import datetime
import os

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def scrape_official_events():
    driver = get_driver()
    event_list = []
    today = datetime.now()

    print("ğŸš€ 4ê°œ í¸ì˜ì  ê³µì‹ í™ˆí˜ì´ì§€ 'ì „ì²´' ì´ë²¤íŠ¸ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. GS25
    print("  -> GS25 ìˆ˜ì§‘ ì¤‘...")
    for page in range(1, 4): 
        try:
            driver.get(f"http://gs25.gsretail.com/gscvs/ko/customer-engagement/event/current-events?pageNum={page}")
            time.sleep(3)
            items = driver.find_elements(By.CSS_SELECTOR, "table.tbl_ltype1 tbody tr")
            if not items: break
            for item in items:
                try:
                    a_tag = item.find_element(By.CSS_SELECTOR, "p.tit a")
                    title = a_tag.text.strip()
                    if not title: continue
                    link = a_tag.get_attribute("href")
                    event_list.append({"brand": "GS25", "title": f"[ê³µì‹] {title}", "link": link, "pub_date": today})
                except Exception: continue
        except Exception: break

    # 2. CU
    print("  -> CU ìˆ˜ì§‘ ì¤‘...")
    for page in range(1, 4):
        try:
            driver.get(f"https://cu.bgfretail.com/brand_info/news_list.do?category=brand_info&depth2=5&sf=N&pageIndex={page}")
            time.sleep(4) 
            rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
            if not rows: break
            for row in rows:
                try:
                    a_tags = row.find_elements(By.TAG_NAME, "a")
                    for a in a_tags:
                        title = a.text.strip()
                        if title and len(title) > 2:
                            title = title.replace('\n', ' ')
                            link = "https://cu.bgfretail.com/brand_info/news_list.do?category=brand_info&depth2=5&sf=N"
                            event_list.append({"brand": "CU", "title": f"[ê³µì‹] {title}", "link": link, "pub_date": today})
                            break 
                except Exception: continue
        except Exception: break

    # 3. 7-Eleven
    print("  -> ì„¸ë¸ì¼ë ˆë¸ ìˆ˜ì§‘ ì¤‘...")
    try:
        driver.get("https://www.7-eleven.co.kr/event/eventList.asp")
        time.sleep(3)
        for _ in range(4): 
            try:
                more_btn = driver.find_element(By.CSS_SELECTOR, "a.btn_more")
                if more_btn.is_displayed():
                    driver.execute_script("arguments[0].click();", more_btn)
                    time.sleep(2)
            except: pass
            
        items = driver.find_elements(By.CSS_SELECTOR, "ul#listUl li")
        for item in items:
            try:
                title = ""
                try: title = item.find_element(By.CSS_SELECTOR, "dt").get_attribute("innerText").strip()
                except: pass
                if not title:
                    try: title = item.find_element(By.CSS_SELECTOR, "img").get_attribute("alt").strip()
                    except: pass
                    
                link = "https://www.7-eleven.co.kr/event/eventList.asp"
                if title:
                    event_list.append({"brand": "ì„¸ë¸ì¼ë ˆë¸", "title": f"[ê³µì‹] {title}", "link": link, "pub_date": today})
            except Exception: continue
    except Exception as e:
        print(f"ì„¸ë¸ì¼ë ˆë¸ ì˜¤ë¥˜: {e}")

    # 4. ì´ë§ˆíŠ¸24 (ì¡°ì¥ë‹˜ì´ ì£¼ì‹  HTML êµ¬ì¡° ì™„ë²½ ë°˜ì˜!)
    print("  -> ì´ë§ˆíŠ¸24 ìˆ˜ì§‘ ì¤‘...")
    try:
        # ì§„í–‰ì¤‘ì¸ ì´ë²¤íŠ¸ ì •í™•í•œ ì£¼ì†Œ ì ìš©
        driver.get("https://emart24.co.kr/event/ing")
        time.sleep(5) # ë°ì´í„°ê°€ ë‹¤ ê·¸ë ¤ì§ˆ ë•Œê¹Œì§€ ë„‰ë„‰íˆ 5ì´ˆ ëŒ€ê¸°
        
        items = driver.find_elements(By.CSS_SELECTOR, "a.eventWrap")
        for item in items:
            try:
                link = item.get_attribute("href")
                if not link: link = "https://emart24.co.kr/event/ing"
                
                # p íƒœê·¸ ì•ˆì˜ ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
                p_text = item.find_element(By.TAG_NAME, "p").get_attribute("innerText").strip()
                if not p_text: continue
                
                lines = [line.strip() for line in p_text.split('\n') if line.strip()]
                # ë‚ ì§œ ë°‘ì— ìˆëŠ” ë§ˆì§€ë§‰ ì¤„ì´ í•­ìƒ í–‰ì‚¬ ì œëª©!
                title = lines[-1] if lines else "ì´ë§ˆíŠ¸24 ì´ë²¤íŠ¸"
                
                event_list.append({"brand": "ì´ë§ˆíŠ¸24", "title": f"[ê³µì‹] {title}", "link": link, "pub_date": today})
            except Exception: continue
    except Exception as e:
        print(f"ì´ë§ˆíŠ¸24 ì˜¤ë¥˜: {e}")

    driver.quit()

    df = pd.DataFrame(event_list)
    if not df.empty:
        df = df.drop_duplicates(subset=['brand', 'title'], keep='first')
        
        save_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, 'official_event_news.csv')
        df.to_csv(save_path, index=False, encoding='utf-8-sig')
        
        print("\nğŸ“Š [ìˆ˜ì§‘ ì™„ë£Œ ë³´ê³ ì„œ]")
        print("------------------------")
        print(df['brand'].value_counts().to_string())
        print("------------------------")
        print(f"âœ… ì´ {len(df)}ê°œì˜ ì´ë²¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    scrape_official_events()