import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime


def crawl_7eleven():
    print("ğŸš€ ì„¸ë¸ì¼ë ˆë¸ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤")

    all_products = []
    # pTab 1: 1+1, pTab 2: 2+1
    event_configs = [(1, "1+1"), (2, "2+1")]

    url = "https://www.7-eleven.co.kr/product/listMoreAjax.asp"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Referer": "https://www.7-eleven.co.kr/product/presentList.asp"
    }

    for p_tab, event_label in event_configs:
        print(f"ğŸ“¦ {event_label} ìƒí’ˆ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

        payload = {
            "intPageSize": 1000000,
            "pTab": p_tab,
            "currPage": 1
        }

        try:
            response = requests.post(url, headers=headers, data=payload)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                items = soup.select("li")

                category_count = 0
                for item in items:
                    try:
                        img_tag = item.select_one(".pic_product img")
                        name = img_tag.get('alt', '').strip() if img_tag else item.select_one(".txt_product").get_text(
                            strip=True)

                        price_text = item.select_one(".price_list span").get_text(strip=True).replace(',', '')
                        price = int(price_text)

                        event = item.select_one(".tag_list_01 li").get_text(strip=True)

                        img_src = img_tag.get('src')
                        img_url = f"https://www.7-eleven.co.kr{img_src}"

                        all_products.append({
                            "brand": "7Eleven",
                            "name": name,
                            "price": price,
                            "event": event,
                            "img_url": img_url
                        })
                        category_count += 1
                    except Exception:
                        continue
        except Exception as e:
            print(f"âŒ {event_label} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

    # --- ë°ì´í„° ì €ì¥ (ì¤‘ë³µ ì œê±° ë¡œì§ ì‚­ì œë¨) ---
    if all_products:
        df = pd.DataFrame(all_products)

        # ì—´ ìˆœì„œ ê³ ì •
        df = df[["brand", "name", "price", "event", "img_url"]]

        today = datetime.now().strftime("%y%m%d")
        file_name = f"7Eleven_{today}.csv"

        # ì¤‘ë³µ ì œê±° ì—†ì´ ë°”ë¡œ ì €ì¥
        df.to_csv(file_name, index=False, encoding='utf-8-sig')
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    crawl_7eleven()